xss: Cross site Scripting: 跨站脚本

在用户访问站点时，在将站点渲染出来的过程中，遇见了一些没有预期到的脚本指令，然后就会执行， 即在用户访问时，插入自己的脚本，
攻击者通过脚本的执行，从而获得用户信息（cookie）。

危害：
1）挂马：将木马程序窜到网站中，再利用木马生成器生成一个网码，再传到空间或者服务器上，在用户打开网站是，木马就会运行。
2）盗取用户cookie：盗取cookie后，模拟成受害用户登录账户，做一些事情
3）DDOS（拒绝服务） 客户端浏览器
4）钓鱼攻击
5）删除目标文章，篡改数据
6）劫持web用户行为，甚至渗透入内网
7）web 2.0的蠕虫病毒
8）蠕虫式挂马攻击，刷广告，刷流量，破坏网上数据


xss 攻击类型 经常混用
1：反射型：服务器端返回脚本，客户端执行
url注入非法脚本，然后发送给受害者，或者服务端返回富文本包含非法脚本，被直接展示  
如：127.0.0.1：9000/reflect？x=<script>alert(2333)</script>
<script>window.location="http://www.google.ca"</script>

2.存储型：后台存储了非法脚本，并且前端直接执行
例如：发帖中包含恶意代码的内容，其他用户访问该内容时，满足条件即出发，但需要前后台展示时不过滤信息

3.DOM-based 型：基于DOM的本地xss攻击
例如：wifi流量劫持，DNS劫持，并且直接返回钓鱼页面，本质是需要更改DOM，再排除自己攻击自己

domxss.html
...
<script>
    eval(location.hash.substr(1));
</script>

访问：127.0.0.1：9000/#alert(document.cookie)



存在的原因：
1. 对url中的参数没有i进行过滤，使一些违法内同可以渗透到服务器端，当用户再次使用时，再违法内容下载到本地使用
2.对用户提交输入的地方没有进行过滤，使一些违法内同可以渗透到服务器端。 当用户再次使用时，再违法内容下载到本地使用
3.充分的过滤是无法实现的，黑客会想尽方法绕过xss过滤系统，所以维护只能加强


xss的防范
对输入（和URL参数）进行过滤，对输出进行编码，cookie设置http-only

1）输入处理：
包括用户输入，URL参数，POST请求参数，AJAX
ex：在过滤时，如<script></script>的内容过滤掉（黑名单过滤策略：设置不可接收的名单，或者白名单：设置可接受的名单，很难完成

2）通过拦截请求完成攻击
通过拦截修改请求包体，在输出数据之前，对潜在不安全字符串进行编码工作，脚本进行转译
转译是通过上下文决定的，ex：<转译为&lt（html entity），\:\\ ....

3)cookie设置成http-only
这样基于不能用js读取cookie，不能信任前端的任何输入，必须要进行校验

Node.js:leizongmin/js-xss
php:
java:naver/lucy-xss-filter

ruby,flask,spring boot 用的是内置防御
